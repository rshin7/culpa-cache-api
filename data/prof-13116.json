{
    "prof_info": [
        {
            "prof_name": "Daniel Hsu",
            "prof_id": 13116,
            "total_reviews": 4
        }
    ],
    "reviews": [
        {
            "course_name": "Machine Learning",
            "review_date": "July 18, 2015",
            "review_content": "\nI am about to say some things that will scare you, but when it comes down to it, you should take this class.\nDaniel:\nDaniel is an expert. This is both good and bad. It is bad because he will sometimes explain things as though we are all on his level, when really no one else is. Additionally, the homework problems can be very challenging and overly mathematical. However, Daniel is more than happy to answer any questions during lectures, so make sure to ask if something gets glossed over. Additionally, you will really understand machine learning after taking this course. I recommend that you print out the slides and take notes on them, as for me they were useless without commentary (because I am not on Daniel's level). \nTAs:\nOur TAs tried really hard, but a few of them fell very short. They often could not help with homework and were unable to answer questions about exams. However, homeworks were graded fairly leniently to make up for this. I was fine with the compromise as I still learned a lot, though it was very frustrating at times when trying to complete difficult homework problems. The best thing was there were a lot of TAs and there were at least one set of office hours each day.\nHomeworks:\nMost homeworks involved a MATLAB component that was never too difficult, and was always my favorite part of the assignments. It was cool to actually apply everything and have a classifier that had a low error. Some people thought that these parts relied too heavily on understanding the tricks of MATLAB, but I always just had long runtimes and didn't bother too much with optimization. I never got points taken off for this. The written parts of the homework could be too mathy for me. Additionally, everything had to be typeset so you couldn't just write it out and then take a picture of it, which always added at least an hour to the write-up. \nExams:\nThe first exam was extremely long. I don't think anyone finished early. It was tough but I think it worked out pretty fair with the curve. The second exam wasn't so long but I thought it was extremely hard. There were some questions that were straight linear algebra without even having an ML twist on them, which I thought was ridiculous as I had taken CLA 2 and a half years before. However, the curve on that ended up okay too and I think the curve overall was also very fair. I did put in at least 90% effort into this class, but I still ended up with a higher grade than I expected.\nReadings:\nThere is a statistics textbook that I couldn't even read it was so over my head. However, the actual ML textbook can be very helpful and is great to read after lectures to clarify things. There weren't as many readings in the second half of the class and I pretty much stopped doing them after the first exam.\nWorkload:\nI took this class with 3 other classes with relatively light workloads, so I found it to be very manageable. I would not recommend taking this course with more than 1 other class with a heavy workload. 5 homeworks, and 2 exams covering the first and last half of the class, both in-class. 40/30/30 distribution I believe.\n"
        },
        {
            "course_name": "Machine Learning",
            "review_date": "May 15, 2015",
            "review_content": "\nThis is a decent class where you will be challenged, put up with lousy instruction but learn a good deal in the process. Daniel Hsu is a super smart professor but about as engaging as a piece of wood. He knows the material in and out and leave you with an appreciation for ML by the end. The class runs pretty smoothly from an operational perspective. The response time on Piazza is insane - Daniel gets back to you in a few hours, especially right before HW deadlines and exams. His answers aren't generally helpful. You see a lot of monosyllabic \"No\"s as answers and he will put you down if your question is stupid or poorly worded (thank god for anonymity). However, when he does deem your question worthy, you get a thorough response.\nThe course assumes you have a decent background in calculus, statistics and linear algebra. Daniel does not pull any punches on the math. If you've taken Calc III, Linear Algebra and Intro to Probability and Stats, you should be fine. You have to be familiar with some matrix calculus, basic probability and stats (multivariate Gaussians, expectations, Baye's rule), projections, eigenvectors and SVD from linear algebra.\nDaniel focuses a lot on a lot of theory in machine learning and less on practice. Lots of long proofs and details on the math behind classification models. I personally think this is excellent since ML is inherently a very mathematical subject and understanding it at this level is key. We covered MLE, generative models, decision tress, linear classifiers, perceptrons, SVM, kernels, some ML theory, boosting, regression, PCA, clustering, entropy, HMMs and some math behind a lot of these topics in detail in their own dedicated lectures. Lots of good stuff!\nIt was impossible to stay awake in class since he turned off the lights in 501 NoCo and is a pretty boring lecturer. He doesn't engage with students unless someone asks a question. Thankfully, his slides are great and available online. I encourage you to try to pay attention in class because sometimes the slides are hard to understand on your own right before the exam at the last minute.\nThe homeworks were reasonable and consisted of a mix of theory and programming questions. They were challenging but nothing you couldn't do by spending some time pouring over the slides and going to office hours. Some of the theory questions were hard and it took my hours reading lecture notes or going to office hours to figure them out. The programming part tends to be simple but you have to vectorize your code for it to take minutes not hours, which can be a bit tricky. Assuming you don't pay attention in lecture (because it's really hard to) and that you have to read the slides from scratch to solve the HW, it takes 8+ hours of work on average. TAs were not helpful since they often couldn't solve the homework themselves.\nHis exams are impossible. Numerical grading on tests and homeworks was very generous and countered the difficulty of the exams. However, his letter grade assignments are on the harsh side.\nI heard StatML with Cunningham is fantastic. He's a great lecturer and focuses on intuition. If you want a more practical course, I would suggest that. If you're a CS major in the Foundations or AI tracks and need ML to count towards your track requirements, you're out of luck. Daniel's class is not bad and I would take it again even though it was a little painful.\nWorkload:\n5 homeworks 40%\n2 in-class exams 30% each - nowhere near enough time for the first one, the second one was insanely hard; only knew the answer to one question properly\n"
        },
        {
            "course_name": "Machine Learning",
            "review_date": "May 08, 2015",
            "review_content": "\nThe only reason not to take this class with Daniel Hsu is if you already have a full workload for the semester. It's great but pretty difficult.\nThe overall curriculum of the course is heavily mathematical. There is relatively little concern with \"real-world\" issues like cleaning data or choosing good features. There were some students who sounded like they wanted a course that would teach them how to apply canned algorithms from sklearn or something. It's more about how to implement those algorithms.\nThe first half covered classification problems of various kinds, followed by some learning theory. There's some statistics which comes from a really interesting and unique perspective. It's the first time I've felt statistics wasn't boring. The second half covered unsupervised learning (clustering, etc.) and Markov models. Sprinkled throughout are theoretical discussions of optimization techniques used to fit various models. Finally, the last few lectures were just topics that the professor thought would be enriching, most notably a lecture on how rating prediction systems like Netflix actually work.\nThe class structure is pretty normal -- readings (that you can get by without doing), lectures, and problem sets, plus two exams.\nThe course had a Piazza board, which the professor was always watching. He would give clear, excellent answers, even at weird hours in the middle of the night. He also remained available the night before a problem set. I thought it was nice that he didn't pretend we had good time management skills, although I agree floating late days would have been good, or at least penalties for late assignments rather than refusing to accept them outright.\nThe lecture slides are all posted online and are detailed and excellent. I didn't need to take any notes. But this doesn't mean it's not worth going to lectures! Prof. Hsu is a good lecturer, although sort of quiet. His explanations perfectly complemented the slides. When students asked questions, he listened carefully and gave very clear and cogent answers.\nWe covered a ton of ground, at a decent level of mathematical sophistication. I think perhaps the professor overestimated our mathematical competence. However, those high expectations along with his good teaching skills made this a great class. Hopefully Columbia keeps him around. \nWorkload:\nProblem sets were difficult but not insanely so. They were usually a mixture of \"easy\" problems to test basic understanding, programming problems, and one or two proofs. There were never any problems that were unsolvable without knowing some kind of trick or having a deep insight -- hard work was always enough to get them.\nThe programming problems were in MATLAB, and usually consisted of training a classifier on a dataset that had already been \"cleaned\" into a nice format. Getting the code to work correctly was usually easy, but the datasets were large enough that efficiency was actually a serious issue, requiring lots of MATLAB tricks.\nExams were another story. There were two non-cumulative exams, both in-class. There was not enough time for the first exam, and the questions for both were quite difficult and often required a lot of creativity under time pressure. It was not enough to just recall the lecture material -- you had to really understand everything on a gut level. The median was very low for both exams. \n"
        },
        {
            "course_name": "Machine Learning",
            "review_date": "May 01, 2015",
            "review_content": "\nTL;DR: Hsu is a solid professor if you're a math-y sort of person who wants derivation, proofs and (by CS standards) rigor. But if you want an easy ML survey course, go take AI, which is pretty much that.\nThe good:\nProfessor Hsu is by no means the most charismatic lecturer at Columbia, but he teaches a solid ML course. His lectures are thorough and rigorous -- he does not succumb to the temptation to use teaching a survey course as an excuse to skim easy topics at a high level -- and the online lecture notes are quite good. \nAlso, it was really nice that the two textbooks the course uses are both available online for free, legally, and that he provided us links to them, unlike so many professors who assign the $300 latest edition of [insert textbook] without giving students' finances a second thought.\nI was absolutely amazed how fast he responds to Piazza questions; he was single-handedly more responsive than a crew of about 8 TAs in another of my classes. The responses, always within a few hours, are sometimes not what the poster is hoping for (monosyllables aren't unusual: quite a few questions get a \"no.\" and no more, particularly if they're stuff like extension requests), but the question is invariably answered in full. And that means stuff like \"what should we review for the final?\" gets answered with a 28-point bulleted list.\nThe bad:\nNo floating late days. There's a reason almost every CS class offers them, and it's both because they avoid all the whining on Piazza from people who put their work off to the last minute and because they provide a way to grant a bit of deadline flexibility without being unfair to anyone. Professor Hsu, if you read this, you really should consider having a few floating late days.\nThe first midterm was to a considerable degree just a speed test (caveat: I didn't feel that way; I mostly missed points for not being able to remember material. But everyone else I spoke to felt it was a speed test) and the curve was, by CS department standards, fairly tough.\nThe lecture hall (the huge one in NoCo) was dimly lit and has poor acoustics, which didn't make staying awake through lecture any easier given that Hsu isn't exactly lecturing at John McWhorter levels of energy most of the time.\nWorkload:\nThe homeworks (5 of them, max 5 hours apiece) weren't particularly hard, and there was a fair bit of hand-holding on them. Personally, I liked the hand-holding because it reinforces the material in a way that blindly guessing your way through a multi-step problem does not, but mileage may vary. Each homework had a programming component, to be done in MATLAB, but Hsu provided code to handle a lot of the tedious/extraneous stuff (e.g. rendering two images side by side); I found the programming to be a really effective introduction to MATLAB, which I'd never used before, and liked being able to focus only on the ML parts of programming.\n2 in-class midterms. \n"
        }
    ]
}